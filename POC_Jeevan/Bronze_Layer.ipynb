{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "104f9bd9-0b14-475a-98d4-f55aa4fb2249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bronze Layer Data Ingestion Summary\n",
    "\n",
    "- Loaded raw CSV data for **students**, **courses**, **enrollments** and **results** \n",
    "- Ingested each dataset into Spark DataFrames with schema inference and header recognition.\n",
    "- Persisted each DataFrame as a **Delta table** in the `kusha_solutions.Jeevan` schema, following the bronze layer convention:\n",
    "  - `bronze_students`\n",
    "  - `bronze_courses`\n",
    "  - `bronze_enrollments`\n",
    "  - `bronze_results`\n",
    "- Ensured overwrite mode and schema consistency for repeatable, reliable ingestion.\n",
    "- Verified data and schema for each bronze table using interactive display and schema printout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5680b31-844c-4d19-b86f-05994a0c60b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the schema (database) name\n",
    "schema_name = \"kusha_solutions.Jeevan\"\n",
    "\n",
    "# Define the path to the students CSV file in DBFS\n",
    "students_csv_path  = \"/Volumes/kusha_solutions/jeevan/my_volume/csv_data/raw/students/students.csv\"\n",
    "\n",
    "# Read the students CSV file into a Spark DataFrame with header and schema inference\n",
    "students_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(students_csv_path)\n",
    "\n",
    "# Write the DataFrame to a Delta table in overwrite mode\n",
    "students_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(f\"{schema_name}.bronze_students\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e550efd-6660-4c77-82e7-e97cd4ec3fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the table name for the bronze_students Delta table in the specified schema\n",
    "table_name = \"kusha_solutions.Jeevan.bronze_students\"\n",
    "\n",
    "# Load the bronze_students table into a Spark DataFrame\n",
    "students_df = spark.table(table_name)\n",
    "\n",
    "# Display the contents of the students DataFrame in a Databricks interactive table\n",
    "display(students_df)\n",
    "\n",
    "# Print the schema of the students DataFrame to show column names and data types\n",
    "students_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2cdc0d6-7e2c-4314-99f4-4875076384b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the schema (database) name\n",
    "schema_name = \"kusha_solutions.Jeevan\"\n",
    "\n",
    "# Define the path to the courses CSV file in DBFS\n",
    "courses_csv_path = \"/Volumes/kusha_solutions/jeevan/my_volume/csv_data/raw/courses/courses.csv\"\n",
    "\n",
    "# Read the courses CSV file into a Spark DataFrame with header and schema inference\n",
    "courses_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(courses_csv_path)\n",
    "\n",
    "# Write the DataFrame to a Delta table in overwrite mode\n",
    "courses_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{schema_name}.bronze_courses\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"✅ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71e83be-ed1d-4b5d-953a-0b3f038a7581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the table name for the bronze_courses Delta table in the specified schema\n",
    "table_name = \"kusha_solutions.Jeevan.bronze_courses\"\n",
    "\n",
    "# Load the bronze_courses table into a Spark DataFrame\n",
    "courses_df = spark.table(table_name)\n",
    "\n",
    "# Display the contents of the courses DataFrame in a Databricks interactive table\n",
    "display(courses_df)\n",
    "\n",
    "# Print the schema of the courses DataFrame to show column names and data types\n",
    "courses_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22160d83-187a-47fc-b7d8-062cf6bfb976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the schema (database) name\n",
    "schema_name = \"kusha_solutions.Jeevan\"\n",
    "\n",
    "# Define the path to the enrollments CSV file in DBFS\n",
    "enrollments_csv_path = \"/Volumes/kusha_solutions/jeevan/my_volume/csv_data/raw/enrollments/enrollments.csv\"\n",
    "\n",
    "# Read the enrollments CSV file into a Spark DataFrame with header and schema inference\n",
    "enrollments_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(enrollments_csv_path)\n",
    "\n",
    "# Write the DataFrame to a Delta table in overwrite mode\n",
    "enrollments_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{schema_name}.bronze_enrollments\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43e539dd-4df4-41eb-9666-a4a81067ac00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify the table name for the bronze_enrollments Delta table in the kusha_solutions.Jeevan schema\n",
    "table_name = \"kusha_solutions.Jeevan.bronze_enrollments\"\n",
    "\n",
    "# Load the bronze_enrollments table into a Spark DataFrame\n",
    "enrollments_df = spark.table(table_name)\n",
    "\n",
    "# Show the contents of the enrollments DataFrame in the Databricks interactive display\n",
    "display(enrollments_df)\n",
    "\n",
    "# Output the schema of the enrollments DataFrame to display column names and data types\n",
    "enrollments_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1da6c863-466d-495a-a8ee-946117a5387a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the schema (database) name\n",
    "schema_name = \"kusha_solutions.Jeevan\"\n",
    "\n",
    "# Define the path to the results CSV file in DBFS\n",
    "results_csv_path     = \"/Volumes/kusha_solutions/jeevan/my_volume/csv_data/raw/results/results.csv\"\n",
    "\n",
    "# Read the results CSV file into a Spark DataFrame with header and schema inference\n",
    "results_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(results_csv_path)\n",
    "\n",
    "# Write the DataFrame to a Delta table in overwrite mode\n",
    "results_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{schema_name}.bronze_results\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"✅ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94bfd7ad-17b7-4d66-a5c0-9c50a07bd933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify the Delta table name for results data in the kusha_solutions.Jeevan schema\n",
    "table_name = \"kusha_solutions.Jeevan.bronze_results\"\n",
    "\n",
    "# Load the bronze_results Delta table into a Spark DataFrame\n",
    "results_df = spark.table(table_name)\n",
    "\n",
    "# Display the contents of the results DataFrame in Databricks interactive table\n",
    "display(results_df)\n",
    "\n",
    "# Print the schema of the results DataFrame to show column names and data types\n",
    "results_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
